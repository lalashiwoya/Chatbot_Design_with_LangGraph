{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You don't have any resources from the local pdfs regarding explainable_ai\n",
      "You don't have any resources from the youtube subtitles regarding explainable_ai\n"
     ]
    }
   ],
   "source": [
    "from utils import init_memory, init_llm\n",
    "from api.create_chain import init_chain\n",
    "from api.create_workflow import custome_workflow\n",
    "from dotenv import load_dotenv\n",
    "from api.utils import get_router_retriever\n",
    "from utils import read_configs_from_toml\n",
    "configs = read_configs_from_toml(\"config.toml\")\n",
    "retriever = get_router_retriever(configs)\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "graph = custome_workflow()\n",
    "llm = init_llm()\n",
    "chains = init_chain(llm)\n",
    "chat_history = init_memory(llm)\n",
    "\n",
    "question=\"how to finetune LLM\"\n",
    "\n",
    "\n",
    "topics = [\"Large Language Model(llm) finetuning\", \"Explanable AI\", \"Heart Disease\"]\n",
    "# workers = {tool_configs[tool]['name']: tool_configs[tool][\"description\"] for tool in tool_configs}\n",
    "workers = {}\n",
    "workers[\"LLM-XAI Knowledge Expert\"] = \"\"\"\n",
    "An Expert in answering questions about Large language models (LLMs) and explainable AI (XAI).\n",
    "\"\"\"\n",
    "\n",
    "workers[\"Heart Disease Expert\"] = \"\"\"\n",
    "An expert in diagnosing heart disease.\n",
    "\"\"\"\n",
    "\n",
    "workers[\"Off-Topic Expert\"] = \"\"\"\n",
    "An Expert in answering questions beyond the given topics.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = configs['topics']['topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_configs = read_configs_from_toml(\"tool_configs.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = {tool_configs[tool]['name']: tool_configs[tool][\"description\"] for tool in tool_configs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = {}\n",
    "workers[\"LLM-XAI Knowledge Expert\"] = \"\"\"\n",
    "An Expert in answering questions about Large language models (LLMs) and explainable AI (XAI).\n",
    "\"\"\"\n",
    "\n",
    "workers[\"Heart Disease Expert\"] = \"\"\"\n",
    "An expert in diagnosing heart disease.\n",
    "\"\"\"\n",
    "\n",
    "workers[\"Off-Topic Expert\"] = \"\"\"\n",
    "An Expert in answering questions beyond the given topics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how to finetune llm\"\n",
    "docs = retriever.get_relevant_documents(\"how to finetune llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To fine-tune a large language model (LLM), it is essential to follow a structured approach. Here are the key steps to finetune an LLM:\\n\\n1. Define the project's vision and scope: Clearly outline the objectives and goals of the LLM project. Determine whether the LLM will be a universal tool or target a specific task within a business or industry.\\n\\n2. Select the appropriate model: Choose between training a model from scratch or modifying an existing one. Consider whether adapting a pre-existing model through fine-tuning is more efficient or if a new model is required.\\n\\n3. Assess model performance: Evaluate the LLM's performance to identify areas for improvement. If the model's results are unsatisfactory, consider prompt engineering or further fine-tuning to enhance its capabilities.\\n\\n4. Iteratively refine the model: Continuously refine the LLM through fine-tuning to optimize its performance and ensure it remains relevant and valuable in the evolving digital landscape.\\n\\nBy following these steps, businesses can effectively fine-tune their LLMs to meet specific requirements and achieve improved accuracy and relevance in generating content.\\n\\nSources:\\n- Source: 3, URL: https://www.superannotate.com/blog/llm-fine-tuning\\n- Source: 2, URL: https://www.superannotate.com/blog/llm-fine-tuning\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chains[\"retrieve\"].invoke({\"context\": docs,\n",
    "                           \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Heart Disease Expert': 'An expert in diagnosing heart disease.\\n'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\"question\": question,\n",
    "         \"chat_history\": chat_history,\n",
    "         \"workers\": workers,\n",
    "         \"chains\": chains,\n",
    "         \"retriever\": retriever,\n",
    "         \"topics\": topics}\n",
    "\n",
    "events = graph.stream(\n",
    "    \n",
    "    input\n",
    ")\n",
    "for s in events:\n",
    "    if 'refine' in s:\n",
    "        result = s['refine']['generation']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To fine-tune a Large Language Model (LLM), you can follow a structured approach that involves defining the project's vision and scope, selecting the appropriate model, assessing model performance, iteratively refining the model, considering specificity and relevance, and enhancing accuracy. By following these steps, you can effectively leverage LLMs to enhance operational processes and achieve more precise results tailored to specific needs.\\n\\nIf you have any further questions on Large Language Models (LLM) finetuning or Explainable AI, feel free to ask for more detailed information on these topics. \\n\\nSources:\\n- Source: 3, URL: https://www.superannotate.com/blog/llm-fine-tuning\\n- Source: 2, URL: https://www.superannotate.com/blog/llm-fine-tuning\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
