{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You don't have any resources from the local pdfs regarding explainable_ai\n",
      "You don't have any resources from the youtube subtitles regarding explainable_ai\n"
     ]
    }
   ],
   "source": [
    "from utils import init_memory, init_llm\n",
    "from api.create_chain import init_chain\n",
    "from api.create_workflow import custome_workflow\n",
    "from dotenv import load_dotenv\n",
    "from api.utils import get_router_retriever\n",
    "from utils import read_configs_from_toml\n",
    "configs = read_configs_from_toml(\"config.toml\")\n",
    "retriever = get_router_retriever(configs)\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "graph = custome_workflow()\n",
    "llm = init_llm()\n",
    "chains = init_chain(llm)\n",
    "chat_history = init_memory(llm)\n",
    "\n",
    "question=\"how to finetune LLM\"\n",
    "\n",
    "\n",
    "topics = [\"Large Language Model(llm) finetuning\", \"Explanable AI\", \"Heart Disease\"]\n",
    "# workers = {tool_configs[tool]['name']: tool_configs[tool][\"description\"] for tool in tool_configs}\n",
    "workers = {}\n",
    "workers[\"LLM-XAI Knowledge Expert\"] = \"\"\"\n",
    "An Expert in answering questions about Large language models (LLMs) and explainable AI (XAI).\n",
    "\"\"\"\n",
    "\n",
    "workers[\"Heart Disease Expert\"] = \"\"\"\n",
    "An expert in diagnosing heart disease.\n",
    "\"\"\"\n",
    "\n",
    "workers[\"Off-Topic Expert\"] = \"\"\"\n",
    "An Expert in answering questions beyond the given topics.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = configs['topics']['topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_configs = read_configs_from_toml(\"tool_configs.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = {tool_configs[tool]['name']: tool_configs[tool][\"description\"] for tool in tool_configs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = {}\n",
    "workers[\"LLM-XAI Knowledge Expert\"] = \"\"\"\n",
    "An Expert in answering questions about Large language models (LLMs) and explainable AI (XAI).\n",
    "\"\"\"\n",
    "\n",
    "workers[\"Heart Disease Expert\"] = \"\"\"\n",
    "An expert in diagnosing heart disease.\n",
    "\"\"\"\n",
    "\n",
    "workers[\"Off-Topic Expert\"] = \"\"\"\n",
    "An Expert in answering questions beyond the given topics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how to finetune llm\"\n",
    "docs = retriever.get_relevant_documents(\"how to finetune llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To fine-tune a large language model (LLM), it is essential to follow a structured approach. Here are the key steps to finetune an LLM:\\n\\n1. Define the project's vision and scope: Clearly outline the objectives and goals of the LLM project. Determine whether the LLM will be a universal tool or target a specific task within a business or industry.\\n\\n2. Select the appropriate model: Choose between training a model from scratch or modifying an existing one. Consider whether adapting a pre-existing model through fine-tuning is more efficient or if a new model is required.\\n\\n3. Assess model performance: Evaluate the LLM's performance to identify areas for improvement. If the model's results are unsatisfactory, consider prompt engineering or further fine-tuning to enhance its capabilities.\\n\\n4. Iteratively refine the model: Continuously refine the LLM through fine-tuning to optimize its performance and ensure it remains relevant and valuable in the evolving digital landscape.\\n\\nBy following these steps, businesses can effectively fine-tune their LLMs to meet specific requirements and achieve improved accuracy and relevance in generating content.\\n\\nSources:\\n- Source: 3, URL: https://www.superannotate.com/blog/llm-fine-tuning\\n- Source: 2, URL: https://www.superannotate.com/blog/llm-fine-tuning\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chains[\"retrieve\"].invoke({\"context\": docs,\n",
    "                           \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Heart Disease Expert': 'An expert in diagnosing heart disease.\\n'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initial_answer': {'generation': [\"To fine-tune a language model (LLM), you can follow these steps:\\n\\n1. Gather a dataset: Collect a dataset of text that is relevant to the task you want the LLM to perform well on.\\n\\n2. Preprocess the data: Clean and preprocess the text data to remove any noise or irrelevant information.\\n\\n3. Choose a pre-trained model: Select a pre-trained language model that you want to fine-tune. Popular choices include GPT-3, BERT, and RoBERTa.\\n\\n4. Fine-tune the model: Use the preprocessed data to fine-tune the selected model on your specific task. This involves updating the model's weights based on your dataset.\\n\\n5. Evaluate the model: Test the fine-tuned model on a separate validation dataset to assess its performance and make any necessary adjustments.\\n\\n6. Iterate: Fine-tuning is an iterative process, so you may need to repeat steps 4 and 5 multiple times to achieve the desired performance.\\n\\nBy following these steps, you can effectively fine-tune a language model for your specific task.\"], 'worker_trace': []}}\n",
      "----\n",
      "{'supervisor': {'worker_trace': ['FINISH'], 'workers': {'Heart Disease Expert': 'An expert in diagnosing heart disease.\\n'}}}\n",
      "----\n",
      "{'refine': {'generation': [\"To fine-tune a language model (LLM), you can follow these steps:\\n\\n1. Gather a dataset: Collect a dataset of text that is relevant to the task you want the LLM to perform well on.\\n\\n2. Preprocess the data: Clean and preprocess the text data to remove any noise or irrelevant information.\\n\\n3. Choose a pre-trained model: Select a pre-trained language model that you want to fine-tune. Popular choices include GPT-3, BERT, and RoBERTa.\\n\\n4. Fine-tune the model: Use the preprocessed data to fine-tune the selected model on your specific task. This involves updating the model's weights based on your dataset.\\n\\n5. Evaluate the model: Test the fine-tuned model on a separate validation dataset to assess its performance and make any necessary adjustments.\\n\\n6. Iterate: Fine-tuning is an iterative process, so you may need to repeat steps 4 and 5 multiple times to achieve the desired performance.\\n\\nBy following these steps, you can effectively fine-tune a language model for your specific task.\", \"I see you are interested in Large Language Models (LLM) finetuning. Here is a refined answer on how to finetune LLM:\\n\\nTo fine-tune a language model (LLM), you can follow these steps:\\n\\n1. Gather a dataset: Collect a dataset of text that is relevant to the task you want the LLM to perform well on.\\n   \\n2. Preprocess the data: Clean and preprocess the text data to remove any noise or irrelevant information.\\n   \\n3. Choose a pre-trained model: Select a pre-trained language model that you want to fine-tune. Popular choices include GPT-3, BERT, and RoBERTa.\\n   \\n4. Fine-tune the model: Use the preprocessed data to fine-tune the selected model on your specific task. This involves updating the model's weights based on your dataset.\\n   \\n5. Evaluate the model: Test the fine-tuned model on a separate validation dataset to assess its performance and make any necessary adjustments.\\n   \\n6. Iterate: Fine-tuning is an iterative process, so you may need to repeat steps 4 and 5 multiple times to achieve the desired performance.\\n\\nBy following these steps, you can effectively fine-tune a language model for your specific task.\\n\\nIf you have any more questions related to Large Language Models (LLM) finetuning or Explainable AI, feel free to ask!\\n\\nSources: N/A\"]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "input = {\"question\": question,\n",
    "         \"chat_history\": chat_history,\n",
    "         \"workers\": workers,\n",
    "         \"chains\": chains,\n",
    "         \"retriever\": retriever,\n",
    "         \"topics\": topics}\n",
    "\n",
    "events = graph.stream(\n",
    "    \n",
    "    input\n",
    ")\n",
    "for s in events:\n",
    "    print(s)\n",
    "    print(\"----\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
